# 2025年华为杯E题：高铁轴承智能故障诊断的全流程实现

本文档详细介绍了为解决“2025年中国研究生数学建模竞赛E题 - 高铁轴承智能故障诊断问题”而构建的一个模块化、可复现的端到端工作流。该工作流遵循**“机理先行、统计为核、迁移对齐、证据闭环”**的核心思想，通过一系列自动化的数据处理、模型训练、迁移学习和可解释性分析流水线，系统地解决了从数据准备到最终诊断和分析的所有挑战。

## 0. 执行脚本

```bash
# === 题目 1 & 2：数据处理与源域模型训练 ===
# 1. 加载和结构化原始数据
python -m src.pipelines.preprocess_pipeline --config src/preprocessing/signal/steps_load_data.yaml

# 2. 提取混合特征 (包含CWT)
python -m src.pipelines.preprocess_pipeline --config src/preprocessing/signal/steps_feature_extraction.yaml

# 3. 训练源域诊断模型
python -m src.pipelines.clf_pipeline --config src/models/clf/XGBoost/params.yaml

# === 题目 3：迁移诊断与目标域标定 ===
# 4.1 执行TCA迁移并预测目标域标签
python -m src.pipelines.transfer_pipeline --config runs/transfer_tca.yaml
# 4.2 执行DANN迁移并预测目标域标签
python -m src.pipelines.dann_pipeline --config runs/transfer_dann.yaml

# === 题目 4：可解释性分析 ===
# 5. 生成SHAP图，解释模型决策
python -m src.pipelines.interpretability_pipeline --config runs/interpret_tca_shap.yaml
```



## 1.项目模块概览

为解决此问题，项目结构扩展如下，新增了针对振动信号处理、迁移学习和可解释性分析的核心模块：

```txt
MathModels/
└── src/
    ├── models/
    │   └── clf/
    │       └── XGBoost/             # 核心分类器模块
    │           ├── build.py
    │           └── params.yaml
    ├── pipelines/
    │   ├── clf_pipeline.py          # 分类模型训练流水线
    │   ├── preprocess_pipeline.py   # 数据预处理流水线
    │   ├── transfer_pipeline.py     # (新增) 迁移诊断流水线
    │   └── interpretability_pipeline.py # (新增) 可解释性分析流水线
    ├── preprocessing/
    │   └── signal/                  # (新增) 信号数据预处理模块
    │       ├── load_bearing_data.py
    │       ├── feature_extraction.py
    │       ├── steps_load_data.yaml
    │       └── steps_feature_extraction.yaml
    └── transfer/
        └── tca.py                   # (新增) TCA迁移算法实现
```

## 2. 题目及工作流介绍

### 题目一

---

#### 原题陈述：

请考虑目标域的迁移任务，从提供的源域数据中筛选部分数据组成数据集。结合轴承故障机理，选择合适的方法或指标对有代表性的源域数据进行**特征分析，**并对整体数据集进行**特征提取**，用于后续诊断任务

---

#### 方案概述：

首先我们应该明确，**本工程的策略不是简单“筛选”，而是“全面、有侧重地提取”**

考虑到迁移任务的目标是让模型在目标域上也能表现良好，一个关键的前提是**源域训练集必须尽可能丰富和多样化，以覆盖可能遇到的各种工况**。因此，我们的策略不是简单地“筛选掉”部分源域数据，而是**使用全部161个源域文件**，并通过以下三个层次化的步骤，来体现题目中的要求：

---

##### **1. 数据集的组成与筛选 (体现在数据加载与划分中)**

> 题目要求：“从提供的源域数据中筛选部分数据组成数据集”

在我们的方案中，这一要求体现在两个层面：

- **宏观层面：使用全部源域数据作为候选集**
  - **体现之处**：`src/preprocessing/signal/load_bearing_data.py` 和 `steps_load_data.yaml` 的设计，旨在加载并处理提供的**所有源域文件**。
  - **理由**：为了让模型具备最强的泛化能力以应对未知的目标域，我们需要让它在训练阶段“见多识广”。源域数据包含了不同的故障类型、尺寸、载荷和转速，全部使用它们可以构建一个更鲁棒的诊断模型。因此，这里的“组成数据集”被我们理解为**构建一个包含所有可用工况的、最全面的训练候选集**。
- **微观层面：通过严格的训练/测试集划分进行“筛选”**
  - **体现之处**：`src/models/clf/XGBoost/build.py` 中的 **StratifiedGroupKFold**。
  - **理由**：这才是“筛选”在统计学上的严谨体现。我们通过这种方式，从全体源域数据中“筛选”出一部分作为**测试集（验证集）**，这部分数据在训练过程中是模型完全不可见的。这确保了我们对模型性能的评估是公平、无偏的，能够真实反映其在迁移到新数据前的泛化能力。

---

##### **2. 结合故障机理的特征分析与提取 (体现在特征工程中)**

> 题目要求：“结合轴承故障机理，选择合适的方法或指标对有代表性的源域数据进行特征分析，并对整体数据集进行特征提取”

这正是我们设计的**混合特征工程**的核心思想，完全在 `src/preprocessing/signal/feature_extraction.py` 中得以体现。我们选择的每一种特征提取方法，都直接对应了题目背景资料中描述的故障机理：

- **包络谱分析 (Envelope Spectrum Analysis)**：
  - **对应机理**：当轴承出现局部缺陷时，滚动体每次碾过缺陷点都会产生一次**冲击脉冲**，这些脉冲以**故障特征频率（`BPFO`, `BPFI`, `BSF`）**周期性地出现。
  - **方法与指标**：我们在 `get_envelope_features` 函数中，通过**希尔伯特变换**来提取信号的包络，然后对包络信号进行`FFT`变换。我们提取的关键指标 **`env_peak_freq`**（包络谱峰值频率），其物理意义就是**寻找这个周期性冲击的主导频率**。如果这个频率与理论计算的某个故障特征频率相匹配，就是故障存在的强烈证据。这是最直接、最核心的机理体现。
- **时域分析 (Time-Domain Analysis)**：
  - **对应机理**：故障产生的冲击脉冲会改变振动信号的**幅值分布和波形形态**。
  - **方法与指标**：我们在 `get_time_domain_features` 函数中提取了**峭度 (`td_kurtosis`)** 和**裕度 (`td_crest_factor`)** 等指标。峭度对信号中的冲击成分特别敏感，一个健康的轴承信号峭度值约等于3，而一个有冲击性故障的信号其峭度值会显著增大。这为判断故障提供了另一维度的证据。
- **时频域分析 (Time-Frequency Analysis)**：
  - **对应机理**：故障冲击是**瞬态的、非平稳的**。传统的FFT分析会丢失冲击发生的时间信息。
  - **方法与指标**：我们在 `get_cwt_features` 函数中引入了**连续小波变换 (CWT)**。CWT能够生成一张时频图，清晰地展示出**在哪个时间点、哪个频率段出现了能量的瞬时集中**。我们提取的 `cwt_energy_*_freq_band` 等指标，就是为了量化这种瞬态能量的分布情况，从而更精细地捕捉故障特征，尤其是在噪声背景下或故障早期阶段。

> ### **混合特征工程的思维逻辑与原理**
>
> 我们的混合特征工程策略包含两个关键步骤：“并行提取”和“拼接融合”。
>
> #### **第一部分：并行提取 (Parallel Extraction) - “多角度勘察”**
>
> 
>
> - **这是什么？** “并行提取”指的是，我们对**同一个**信号窗口（可以把它想象成一段短暂的振动“录音”），**同时**应用四套完全不同的分析算法（时域、频域、包络谱、时频域），从四个不同的“视角”去审视它。
> - **为什么要这么做？—— 原理：故障特征的多面性** 轴承的故障信号是一个极其复杂的物理现象，它绝对不是单一维度能够完整描述的。我们可以把它比作一个“犯罪现场”，而我们的特征提取算法就是四位不同领域的“法医专家”：
>   1. **时域专家 (`get_time_domain_features`)**：
>      - **工具**：统计学（均值、峭度、裕度因子等）。
>      - **勘察视角**：不关心细节，只看整体的“暴力程度”。他会报告：“现场的能量 (`td_rms`) 非常高，并且有剧烈冲击的迹象（`td_kurtosis` 峭度值很大）。” 这为我们提供了故障存在与否的初步判断。
>   2. **频域专家 (`get_freq_domain_features`)**：
>      - **工具**：傅里叶变换 (FFT)。
>      - **勘察视角**：寻找现场是否有某种“主旋律”或“共振”。他可能会报告：“我发现现场的主要能量都集中在 1324 Hz (`fd_peak_freq`) 这个频率上。” 这可能暗示了某种系统性的异常。
>   3. **包络谱专家 (`get_envelope_features`)**：
>      - **工具**：希尔伯特变换。
>      - **勘察视角**：他是最懂轴承故障机理的专家，专门寻找由故障引起的**周期性冲击**。他会报告：“我过滤掉了所有无关的高频噪音，发现了一个频率为 64.4 Hz (`env_peak_freq`) 的、非常有规律的敲击声。根据档案，这个频率和滚动体故障的特征频率高度吻合！” 这是判断**故障类型**的最直接证据。
>   4. **时频域专家 (`get_cwt_features`)**：
>      - **工具**：连续小波变换 (CWT)。
>      - **勘察视角**：他拥有“高速摄像机”，能捕捉到**转瞬即逝**的现象。他会报告：“我发现在某个精确的时间点，中频段的能量 (`cwt_energy_mid_freq_band`) 突然爆发了一下，虽然很快就消失了。” 这对于捕捉早期、不稳定的故障信号至关重要。
>
> **并行提取的结论**：任何单一维度的特征都可能因为噪声、工况变化而失效。通过并行提取，我们为每一个信号窗口生成了一份**全面的“法医报告”**，从四个互补的、基于不同物理原理的视角，完整地刻画了它的状态。
>
> #### **第二部分：拼接融合 (Concatenation Fusion) - “专家会诊”**
>
> 
>
> - **这是什么？** “拼接融合”指的是，我们将上述四位“专家”各自的报告（即他们提取出的特征值），简单地**并排拼接**在一起，形成一个很长的、高维的特征向量。 `[td_mean, td_std, ..., fd_peak_freq, ..., env_peak_freq, ..., cwt_energy_mid]`
> - **为什么要这么做？—— 原理：让强模型学习特征间的协同效应** 这背后是我们对现代机器学习模型能力的深刻理解。
>   1. **信息无损**：简单的拼接，保证了我们从每个维度提取的所有信息都**原封不动地保留**了下来，没有任何损失。
>   2. **暴露交互关系**：将所有特征放在同一个向量里，就给了模型一个**全局的视角**，让它有机会去发现特征之间的**协同效应（Synergy）或交互关系**。
>      - **一个经典的例子**：
>        - 单独看 `td_kurtosis` (峭度) 很高，可能说明有冲击，但无法确定是什么故障。
>        - 单独看 `env_peak_freq` (包络谱峰频) 等于 100 Hz，可能只是巧合。
>        - **但是**，当一个强大的模型（如XGBoost）**同时看到** `td_kurtosis` 很高 **并且** `env_peak_freq` 恰好等于理论上的内圈故障频率时，它就能学习到一个非常强大的组合规则：“**高冲击性 + 特定重复频率 = 高概率内圈故障**”。
>   3. **信任强模型**：这正是我们选择XGBoost的原因。XGBoost这样的集成树模型，其本质就是成百上千个“小决策规则”的集合，它**极其擅长**在数百个特征中自动地、高效地发现并利用这种高阶的、非线性的交互关系。
>      - **对比**：如果我们采用“分离式模型+投票”的方案，就等于强迫每个“专家”独立做出判断，最后简单地“举手表决”。这种方式**完全忽略了专家们之间的信息交流和协同判断**，丢失了大量宝贵的交互信息，因此其性能上限通常低于“混合特征+强模型”的方案。
>
> **拼接融合的结论**：我们采用拼接融合，本质上是**将“如何融合不同维度信息”这个复杂的任务，从需要人类专家凭经验设计规则，转变为让强大的机器学习模型在数据中自动、最优化地学习**。这是现代数据科学的一个核心思想，也是我们方案先进性的体现。

---

#### **总结：我们的方案是如何体现题目要求的**

1. **数据筛选与组成**：我们通过**加载全部源域数据**来保证模型的泛化能力，并通过**严格的“分组分层”交叉验证**来科学地“筛选”出独立的测试集进行评估。
2. **特征分析与提取**：我们的整个特征提取流水线 (`feature_extraction.py`) 就是一个**基于故障机理的分析过程**。我们没有使用盲目的、不可解释的特征，而是选择了**包络谱、时域统计量、CWT**这三大类方法，它们分别从“周期性冲击”、“波形形态”和“瞬态特性”三个维度，全面地、有机理地刻画了轴承的健康状态。
3. **应用于整体数据集**：该流水线被设计为对 `manifest.csv` 中列出的**所有数据（包括源域和目标域）**进行统一处理，生成最终的 `features.parquet` 文件。这确保了在后续的迁移任务中，源域和目标域的特征是在完全相同的标准下提取的，具备可比性。

---

#### 相关文件及参数含义

| 文件名                                                   | 文件作用 (Role in Workflow) | 文件内容介绍 (Content Description)                           |
| -------------------------------------------------------- | --------------------------- | ------------------------------------------------------------ |
| `data/source_domain/*` `data/target_domain/*`            | **原始数据输入**            | 存放所有原始的 `.mat` 格式轴承振动信号文件。这是整个分析流程的起点。 |
| `src/preprocessing/signal/steps_load_data.yaml`          | **加载阶段-配置文件**       | 指示数据加载流水线 (`preprocess_pipeline.py`) 执行 `load_bearing_data` 任务，并为其提供输入（原始数据目录）和输出（序列化信号目录）的路径。 |
| `src/preprocessing/signal/load_bearing_data.py`          | **加载阶段-核心逻辑**       | 执行数据加载和结构化的核心脚本。它递归地扫描输入目录，解析 `.mat` 文件，提取信号数据和元信息，并将它们转换为统一的、结构化的格式。 |
| `outputs/data/artifacts/signal_parquet/*`                | **加载阶段-中间产物**       | **序列化的信号文件**。每个 Parquet 文件包含从一个原始 `.mat` 文件中提取的一段纯净的一维振动信号数组。采用列式存储，I/O效率高。 |
| `outputs/data/artifacts/manifest.csv`                    | **加载与特征提取的桥梁**    | **元数据总清单**。这是承上启下的关键文件，作为后续步骤的“数据地图”。 - `domain`: 数据来源（'source' 或 'target'）。 - `original_file`: 原始的.mat文件名。 - `sensor`: 传感器位置 (DE, FE, BA)。 - `rpm`: 转速。 - `fault_type`: 故障类型。 - `fault_size`: 故障尺寸。 - `load`: 载荷。 - `signal_path`: 指向对应的 Parquet 信号文件的路径。 |
| `src/preprocessing/signal/steps_feature_extraction.yaml` | **特征提取-配置文件**       | 指示数据提取流水线 (`preprocess_pipeline.py`) 执行 `extract_signal_features` 任务，并为其提供核心参数，如统一采样率、分窗大小和重叠率。 |
| `src/preprocessing/signal/feature_extraction.py`         | **特征提取-核心逻辑**       | 执行特征提取的核心脚本。它读取 `manifest.csv`，根据路径找到每个信号，进行重采样和分窗，然后应用多种方法（时域、频域、包络谱、CWT）提取混合特征。 |
| `outputs/data/artifacts/features.parquet`                | **题目一的最终产出**        | **特征总表**。这是机器学习模型可以直接使用的最终输入。每一行代表一个信号窗口，每一列代表一个特征。 - `window_id`: 每个窗口的唯一标识。 - `td_*`: 各种**时域**特征（如均值 `_mean`, 峭度 `_kurtosis`）。 - `fd_*`: 各种**频域**特征（如峰值频率 `_peak_freq`）。 - `env_*`: 各种**包络谱**特征。 - `cwt_*`: 各种**时频域(CWT)**特征（如总能量 `_total_energy`）。 - (其余列): 从`manifest.csv`继承的元数据。 |

### 题目二

---

#### 原题陈述：

**源域故障诊断**：在任务1提取的故障特征基础上，划分源域训练集与测试集。设计合适的诊断模型实现源域诊断任务，并对诊断结果进行评价

---

#### 方案概述：

##### 1. 划分源域训练集与测试集

我们采用了一种在处理此类数据时至关重要的**“严格防泄漏”**的划分方法，即**分组分层K折交叉验证 (StratifiedGroupKFold)**。

> #### **1. Group (分组) - 防止数据泄漏的核心**
>
> - **这是什么？** `Group` 是这个方法中最关键的部分。它要求我们在划分数据时，提供一个**“分组标签”**。在我们的项目中，这个分组标签就是 `original_file`，即每个数据窗口来源于哪个原始的 `.mat` 文件。
> - **它的工作原理是什么？** `GroupKFold` 遵循一个**铁律**：**所有拥有相同分组标签的样本（数据窗口），必须同生共死，要么全部进入训练集，要么全部进入测试集，绝不能被分开。**
>   - 在我们的比喻中，这意味着来自莎士比亚这本书的所有100张卡片，要么全部被划为“学习材料”，要么全部被划为“考试卷”。
>   - 在我们的项目中，这意味着来自 `B007_0.mat` 这个文件的所有几百个数据窗口，要么全部用于训练，要么全部用于测试。
> - **为什么这至关重要？** 这完美地解决了**数据泄漏**的问题。模型在训练时，看到的将是来自一部分 `.mat` 文件的全部信息。而在测试时，它将面对的是来自**完全陌生**的另一部分 `.mat` 文件的挑战。这**真实地模拟了模型在未来被部署后，去诊断一个全新的、从未见过的轴承信号时的场景**。在这种严格的“闭卷考试”下得到的分数，才是对模型真实泛化能力的可靠评估。
>
> #### **2. Stratified (分层) - 保证类别平衡**
>
> - **这是什么？** `Stratified` 的作用是**保持数据集中各类别的原始比例**。
> - **它的工作原理是什么？** 在进行分组划分的同时，它会尽力确保在最终生成的训练集和测试集中，不同故障类别（'Normal', 'Ball', 'InnerRace', 'OuterRace'）的**样本比例与整个源域数据集中的比例大致相同**。
>   - 例如，如果原始数据集中“正常”样本只占5%，那么在划分后的训练集和测试集中，“正常”样本的比例也都会约等于5%。
> - **为什么这至关重要？** 我们的轴承故障数据是**类别不均衡**的（例如，正常样本远少于故障样本）。如果不进行分层，一次随机的划分很可能导致测试集中一个“正常”样本都没有，那我们就完全无法评估模型识别正常状态的能力了。分层确保了**每一个类别都能在训练和测试中得到公平的体现**，使得我们的评估更加全面和可靠。
>
> #### **3. K-Fold (K折交叉验证)**
>
> - **这是什么？** `K-Fold` 是一种经典的交叉验证方法，用于更鲁棒地评估模型性能。
> - **它的工作原理是什么？** 它将整个数据集分成 K 份（在我们的配置中，K=5）。然后进行 K 次独立的训练和评估：
>   - 第1次：用第1份做测试集，其余4份做训练集。
>   - 第2次：用第2份做测试集，其余4份做训练集。
>   - ...
>   - 第5次：用第5份做测试集，其余4份做训练集。 最终模型的性能是这 K 次评估结果的平均值。
> - **为什么这至关重要？** 只进行一次简单的训练-测试划分，其结果可能带有偶然性（可能碰巧分到了一组特别简单或特别难的测试数据）。K折交叉验证通过多次、无重复的划分，让**每一份数据都有机会成为一次测试集**，从而得出一个更稳定、更具说服力的性能评估结果。在我们的项目中，为了简化流程，我们只执行了其中的一次划分 (`next(splitter.split(...))`)，但这个框架允许我们轻松地扩展为完整的K折验证。

- **实现方法**：

  - **代码**：此方法在 `src/models/clf/XGBoost/build.py` 文件的 `fit` 函数中实现。

  - **核心逻辑**：

    ```Python
    # 关键代码片段
    splitter = StratifiedGroupKFold(n_splits=cfg["split"]["n_splits"], shuffle=True, random_state=cfg.get("seed", 42))
    train_idx, val_idx = next(splitter.split(X, y, groups=source_df["original_file"]))
    ```

- **为何这么做？**

  - **分组 (`groups=source_df["original_file"]`)**：这是防止**数据泄漏**的关键。由于我们的特征数据是通过对原始信号进行“分窗”得到的，来自同一个原始 `.mat` 文件的多个数据窗口（样本）之间具有高度相关性。如果采用简单的随机划分，可能会导致同一个原始文件的部分窗口出现在训练集，另一部分出现在测试集。这会让模型在训练时“偷看到”测试集的信息，从而导致模型在验证集上的性能被**严重高估**，无法真实反映其泛化能力。通过按 `original_file` 分组，我们确保了**来自同一个原始文件的所有窗口要么都在训练集，要么都在测试集**，模拟了模型在面对一个完全未知的新轴承数据时的真实场景。
  - **分层 (`Stratified`)**：这确保了在划分后的训练集和测试集中，不同故障类别（如'Normal', 'Ball', 'InnerRace'）的**比例与原始数据集中保持一致**。这对于处理本身就类别不均衡的故障数据至关重要，避免了因随机划分导致某个测试集中缺少某类故障样本的情况。

- **最终划分结果**：

  - **训练集**：由 `train_idx` 索引的样本，用于训练XGBoost模型。
  - **测试集（验证集）**：由 `val_idx` 索引的样本，用于评估模型性能并生成报告。在我们的流水线中，我们使用5折交叉验证中的第1折作为测试集

##### 2. 设计合适的诊断模型

在完成了特征提取和数据集划分后，任务的核心是设计一个能够充分利用这些特征、实现高精度诊断的模型。我们的设计思路是“**强模型配强特征**”，即选择一个足够强大和先进的机器学习模型，来匹配我们在任务一中精心构建的多模态混合特征集。

- **诊断模型的设计与选择**

> 最终选择：**XGBoost (eXtreme Gradient Boosting)** 作为我们的核心诊断模型。

- **实现方法**：
  - **代码**：模型的核心逻辑在 `src/models/clf/XGBoost/build.py` 文件中定义。
  - **配置**：模型的超参数在 `src/models/clf/XGBoost/params.yaml` 文件中进行配置，这使得我们可以方便地进行调优实验。
- **为何选择XGBoost？——与备选方案的对比**：
  - **备选方案1：传统统计模型（如逻辑回归）**：这类模型结构简单、可解释性强。但它们的线性假设限制了其学习能力，无法有效捕捉到不同特征（如峭度、包络谱频率、小波能量）之间复杂的、非线性的交互关系。对于我们构建的高维混合特征集，使用简单模型会造成**信息浪费**，性能难以达到最优。
  - **备选方案2：其他集成模型（如随机森林）**：随机森林也是一个非常强大的模型。但XGBoost作为一种**梯度提升（Boosting）算法，其核心思想是迭代地训练一系列弱学习器（决策树），每一棵新树都在弥补前面所有树的不足**。这种机制使得XGBoost在许多竞赛和实际应用中，其精度上限通常能超越随机森林。
  - **最终决策**：我们选择XGBoost，因为它在处理复杂的表格数据、高维特征以及类别不均衡问题上，都展现出了业界公认的卓越性能和鲁棒性。它有能力从我们丰富的混合特征集中**自动学习出高阶的、有判别力的组合规则**，是实现高精度诊断的理想选择。

- **诊断模型如何实现诊断任务？**

  我们的诊断模型通过一个标准化的、自动化的流水线 (`clf_pipeline.py`) 来完成诊断任务，其具体**实现步骤**如下：

	1. **加载数据**：流水线首先读取在任务一中生成的最终产物——`outputs/data/artifacts/features.parquet` 特征总表。
	1. **特征与标签分离**：在 `XGBoost/build.py` 中，脚本自动筛选出所有以 `td_`, `fd_`, `env_`, `cwt_` 开头的列作为模型的输入特征 `X`，并将 `fault_type` 列作为待预测的目标标签 `y`。
	1. **标签编码**：由于机器学习模型只能处理数字，我们使用 `LabelEncoder` 将文本格式的故障类型（如 'Normal', 'Ball'）转换为数值（如 0, 1）。
	1. **模型训练**：脚本调用 `XGBClassifier` 的 `.fit()` 方法，将在第一步划分好的**训练集** (`X_tr`, `y_tr`) 上进行训练。在这个过程中，XGBoost会构建数百棵决策树，学习从输入的特征组合到最终故障类型的复杂映射关系。
	1. **诊断（预测）**：训练完成后，调用模型的 `.predict()` 和 `.predict_proba()` 方法，对独立的**测试集（验证集）** (`X_val`) 进行预测，输出每个样本的诊断结果和对应的置信度概率。
	1. **结果评价**：最后，我们将模型的诊断结果与真实的标签进行比较，并通过 `src/core/metrics.py` 模块计算一系列性能指标（如准确率、F1分数），并生成混淆矩阵等可视化报告，以全面、客观地评价诊断模型的性能。

#### 相关文件及参数含义

| 文件名 (File Name)                                           | 文件作用 (Role in Workflow) | 文件内容介绍 (Content Description)                           |
| ------------------------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| `outputs/data/artifacts/features.parquet`                    | **模型输入-特征数据**       | 作为诊断模型的直接输入。这是在题目一中生成的特征总表，每一行代表一个信号窗口，包含了我们设计的时域、频域、包络谱和CWT等多模态混合特征。 |
| `src/models/clf/XGBoost/params.yaml`                         | **模型训练-主配置文件**     | 定义了本次源域诊断任务的所有配置，包括使用哪个模型（XGBoost）、输入哪个特征文件、如何划分数据集、模型的超参数、评估指标以及所有输出文件的命名标签。 |
| `src/pipelines/clf_pipeline.py`                              | **模型训练-执行流水线**     | 整个诊断任务的“调度中心”。它负责解析配置文件，加载数据，调用正确的模型模块 (`XGBoost/build.py`)，并执行训练、评估和保存产出物的完整流程。 |
| `src/models/clf/XGBoost/build.py`                            | **模型训练-核心逻辑**       | 包含了XGBoost模型从数据准备（标签编码、防泄漏划分）到训练 (`.fit`)、预测 (`.predict`) 和评估的全部核心代码。 |
| `src/core/metrics.py`                                        | **结果评估-指标计算**       | 提供了标准化的函数来计算模型的性能。在诊断任务结束后，`build.py`会调用此文件中的函数来生成最终的评估分数。 |
| `outputs/models/source_xgb_baseline.pkl`                     | **产出物-训练好的模型**     | **知识的载体**。这是一个序列化的Python对象，内部封装了训练好的XGBoost模型。它是本阶段的核心产出，可用于后续的迁移学习和可解释性分析。 |
| `outputs/models/source_xgb_baseline_label_encoder.pkl`       | **产出物-标签编码器**       | 序列化的标签编码器对象。它记录了故障类型文本（如'Ball'）与数字（如'1'）之间的映射关系，用于在预测后将数字结果转换回人类可读的标签。 |
| `outputs/data/predictions/XGBoost/source_xgb_baseline_preds.csv` | **产出物-诊断结果详情**     | CSV表格，记录了模型在独立的验证集上的详细预测情况。<br /> - `true_label`: 该数据窗口**真实**的故障类型。 <br />- `pred_label`: 模型**预测**的故障类型。 <br />- `proba_*`: 模型预测为每个具体故障类别的**置信度概率**（0到1之间），值越高代表模型对该预测越有信心。 |
| `outputs/reports/source_xgb_baseline_metrics.json`           | **产出物-性能评估报告**     | JSON格式的最终性能报告，包含了关键的评估指标。 <br />- **`ACC` (Accuracy)**: **准确率**，表示模型正确分类的样本比例（0-1之间）。**评分标准**：值越接近1，表示模型整体性能越好。<br /> - **`F1` (Macro F1-Score)**: **宏平均F1分数**（0-1之间）。它是精确率和召回率的调和平均数，在处理类别不均衡问题时比准确率更具参考价值。**评分标准**：值越接近1，表示模型在所有类别上的综合表现越好。 <br />- **`ROC_AUC`**: **ROC曲线下面积**（0.5-1之间）。衡量模型区分不同类别的能力。**评分标准**：值越接近1，说明模型的区分能力越强；0.5表示随机猜测。 |
| `outputs/figs/clf/source_xgb_baseline_cm.png`                | **产出物-结果可视化**       | **混淆矩阵**图像。 **如何解读**：这是一个N×N的方阵（N为故障类别数）。 - **对角线（左上到右下）**：表示模型**预测正确**的样本数量。对角线上的数值越大、颜色越深，说明模型对该类别的识别效果越好。 <br />- **非对角线**：表示模型**预测错误**的情况。例如，第i行第j列的数值表示有N个本应是第i类的样本被错误地预测为了第j类。通过观察非对角线上的亮点，可以直观地发现模型**在哪几类故障之间最容易混淆**。 |

### 题目三

---

#### 原题陈述：

在任务2设计的诊断模型基础上，充分考虑源域与目标域的共性与差异特征，设计合适的迁移学习方法，构建目标域诊断模型，对目标域未知标签的数据进行分类和标定，给出迁移结果的可视化展示和分析，并给出数据对应的标签。

---

#### 方案概述：

为了解决题目三，我们设计并实现了一个独立的、自动化的迁移学习流水线——`transfer_pipeline.py`。这个流水线系统性地完成了从领域差异分析、模型迁移、目标域标定到结果可视化的全部任务。

##### 1. 充分考虑源域与目标域的共性与差异特征

这是设计迁移学习方法的**前提和动机**。

- **差异特征 (Domain Shift) 的体现**：
  - **根本原因**：源域（台架实验）和目标域（在途列车）的工况（如载荷、转速、噪声环境）存在显著差异，导致它们的振动信号数据分布不同。这就是“领域偏移”或“领域差异”。
  - **在工作流中的体现**：我们的流水线首先通过 **t-SNE 降维可视化**来直观地展示这一差异。
    - **产出文件**：`outputs/figs/transfer/tsne_before_tca.png`
    - **分析**：在这张图中，代表源域的蓝色点云和代表目标域的红色点云形成了**明显分离**的两个簇。这张图本身就是我们对“差异特征”的**定量分析和可视化证明**，它雄辩地说明了为什么不能将在任务二中训练的模型直接应用于目标域，也确立了进行领域自适应的必要性。
- **共性特征 (Shared Features) 的体现**：
  - **根本原因**：根据题目背景，尽管工况不同，但轴承发生故障（如内圈、外圈、滚动体损伤）的**物理机理是相同的**。例如，滚动体碾过损伤点时产生的周期性冲击是故障的根本物理表征。
  - **在工作流中的体现**：我们在任务一的特征工程 (`feature_extraction.py`) 中提取的**混合特征集**，就是为了捕捉这些共性特征而精心设计的。
    - `env_*` 特征（包络谱）旨在捕捉周期性冲击。
    - `cwt_*` 特征（小波变换）旨在捕捉瞬态冲击。
    - `td_*` 特征（时域）旨在捕捉信号波形的整体形态。
  - 这些基于物理机理的特征是两个领域之间的“共同语言”，是知识能够成功迁移的**物理基础**。

##### 2. 设计合适的迁移学习方法

在充分理解了域间差异和共性的基础上，我们设计了以下迁移学习方案。

- **选择的方法**：我们选择了基于特征迁移的**迁移成分分析 (TCA, Transfer Component Analysis)** 算法。

> ### **差异特征 (Domain Shift) 的原理与体现**
>
> Q1: 什么是领域偏移 (Domain Shift)？
>
> A1: 在机器学习中，领域偏移是一个核心概念，它指的是**训练数据集（源域）的概率分布与测试数据集（目标域）的概率分布不一致**。
>
> - **理想情况**：在一个标准的机器学习任务中，我们假设训练数据和测试数据是“独立同分布”的。这意味着模型在训练时学习到的规律，可以无缝地应用到测试数据上。
> - **现实问题**：在许多实际场景中，这个假设不成立。我们辛辛苦苦在实验室（源域）收集了大量数据训练出一个高精度模型，但当把它部署到真实世界（目标域）时，性能却一落千丈。根本原因就是两个领域的数据分布存在差异，模型在源域学到的“规则”在目标域不再完全适用。
>
> **导致本项目中领域偏移的物理原理**
>
> 在本项目中，源域（台架实验）和目标域（在途列车）之间的领域偏移并非随机的，而是由一系列深刻的**物理和工程因素**共同导致的。我们可以从以下几个方面来理解：
>
> - **工况差异 (Operating Conditions)**:
>   - **源域**：台架实验是在**受控、理想化**的环境下进行的。载荷是固定的（0, 1, 2, 3马力），转速也是相对稳定的。
>   - **目标域**：在途列车则处于**复杂、多变**的真实运营工况中。列车会经历加速、减速、过弯、上下坡等过程，导致轴承承受的载荷和转速是**动态、连续变化**的。这种变化会直接影响振动信号的幅值和频率成分。
> - **噪声与干扰 (Noise and Interference)**:
>   - **源域**：台架实验环境相对“纯净”，噪声主要来自电机本身，影响较小 (“存在轻微噪声影响”)。
>   - **目标域**：在途列车的传感器采集到的信号，会混入大量**强烈的背景噪声和干扰** (“受复杂运行环境与多变工况的影响，传感器采集的原始振动信号易受到背景噪声、干扰源响应等诸多成分影响”)。这些噪声可以来自：
>     - 轮轨接触的轰鸣声。
>     - 整个转向架（Bogie）的复杂振动。
>     - 气动噪声。
>     - 其他机械部件的共振。 这些强噪声会**淹没或扭曲**由轴承故障产生的微弱冲击信号，使得故障特征的显著性大大降低。
> - **振动传递路径 (Vibration Transmission Path)**:
>   - **源域**：传感器直接安装在试验台的电机壳体上，距离轴承非常近，振动传递路径短而直接。
>   - **目标域**：在途列车的传感器安装在轴箱上，振动信号从轴承产生后，需要经过轴、轴承座、轴箱体等多个部件才能到达传感器。这个更长的传递路径会使信号，特别是高频成分，发生**衰减和失真**。
>
> 这些物理和工程上的差异，最终导致了两个领域的数据在**特征空间**中的分布完全不同。例如，同一个“内圈故障”，在目标域的信号中，其时域峭度（`td_kurtosis`）可能因为强背景噪声而低于源域；其包络谱峰值频率（`env_peak_freq`）可能因为信号衰减而幅值更小。
>
> Q2: 如何通过 t-SNE 可视化来体现领域偏移?
>
> A2: 我们知道了领域偏移的存在，证明并展示它的方式，就是 `tsne_before_tca.png` 这张图
>
> - **t-SNE 算法的原理**：
>   - t-SNE 是一种强大的**非线性降维算法**，它的核心目标是将高维数据（在我们的项目中，是包含21个特征的特征向量）投影到二维或三维空间中，以便于人类观察。
>   - 它的工作方式可以通俗地理解为：在原始的高维空间中，它会计算每两个数据点之间的“相似度”。然后，它尝试在二维平面上重新摆放这些点，使得在高维空间中“相似”的点在二维平面上**距离很近**，而在高维空间中“不相似”的点在二维平面上**距离很远**。
> - **`tsne_before_tca.png` 的解读**：
>   1. **输入**：我们将源域和目标域的**所有高维特征向量**（每个向量21维）一同输入给 t-SNE 算法。
>   2. **过程**：t-SNE 开始在二维平面上“摆放”这些点。
>   3. **输出与分析**：
>      - 我们观察到，最终的图像呈现出**两个明显分离的点云**：一个是由代表源域的蓝色点组成的簇，另一个是由代表目标域的红色点组成的簇。
>      - **这张图的深刻含义是**：t-SNE 算法发现，在21维的特征空间中，任意一个源域样本点，与**其他源域样本点**的“相似度”，要远大于它与**任何一个目标域样本点**的“相似度”。反之亦然。
>      - 因此，这两个分离的点云，就是**领域偏移最直观、最强有力的视觉证据**。它告诉我们，这两个数据集在特征空间中“生活在两个不同的世界”，如果我们在一个“世界”（源域）里学习规则，然后直接用到另一个“世界”（目标域）里，失败的概率会非常高。这也为我们后续必须采用TCA等迁移学习方法来“打通”这两个世界，提供了坚实的理论和视觉依据。

- **实现位置**：
  - 该算法的核心逻辑在 `src/transfer/tca.py` 文件中实现。
  - 整个迁移流程由 `src/pipelines/transfer_pipeline.py` 调度执行。
- **方法原理与适用性**：TCA旨在学习一个**共享的潜在子空间**，将源域和目标域的数据都投影到这个空间中。其核心是通过最小化**最大均值差异 (MMD)**，来使得投影后两个域的数据分布尽可能地接近。这种方法能够对齐两个分布的整体形态（包括均值、方差、偏度等高阶矩），而不仅仅是简单的统计量，因此非常适合处理由不同工况导致的复杂、非线性的分布差异，完美地解决了我们在第一步中识别出的“领域偏移”问题。

> ### 一个核心比喻：学习“普通话”
>
> 想象一下：
>
> - **源域（台架实验数据）** 就像一个说话带浓重**“实验室方言”**的人。他说的话（特征）非常有规律，也很清晰，我们很容易就能训练一个“方言识别模型”（任务二的XGBoost模型）来听懂他。
> - **目标域（在途列车数据）** 就像一个说话带**“现场方言”**的人。他说的话（特征）和“实验室方言”在口音、语速、背景噪音上都完全不同，虽然他们描述的是同样的事情（轴承故障）。
> - **领域偏移 (Domain Shift)**：就是这两种方言之间的巨大差异。直接用“实验室方言识别模型”去听“现场方言”，效果肯定很差。
>
> **迁移学习的目标**：不是让“实验室方言”模型去硬着头皮听“现场方言”。而是**创造一种通用的“普通话”**，并教会两个说方言的人都用这种“普通话”来表达自己。
>
> **TCA算法的作用**：就是这个**“普通话编译器”**。它能找到一种转换规则，将“实验室方言”和“现场方言”都翻译成一种标准的“普通话”（即对齐后的共享特征空间）。在这个“普通话”空间里，两个人的表达方式就变得非常相似了。
>
> ---
>
> ### **迁移学习的原理与实现步骤**
>
> 我们的迁移学习正是遵循上述比喻的逻辑，通过**迁移成分分析 (TCA)** 算法来实现的。其核心原理是**最小化最大均值差异 (MMD)**。
>
> #### **第一步：识别问题 —— 无法直接迁移**
>
> - **原理**：我们已经通过 `tsne_before_tca.png` 证明了源域和目标域的数据分布存在巨大差异（领域偏移）。
> - **结论**：在任务二中训练的 `source_xgb_baseline.pkl` 模型，它只搞得懂原始特征空间。我们不能直接用它来诊断目标域数据。
>
> #### **第二步：找到对齐规则 —— 学习转换矩阵 W (TCA 的核心)**
>
> 这是迁移的**关键**，在 `tca.py` 的 `fit()` 方法中实现。
>
> - **核心原理：最小化最大均值差异 (MMD)**
>   - MMD 是一个强大的数学工具，可以用来衡量两组数据（比如源域和目标域）的分布有多么不同。可以把它理解为两堆沙子形状差异的“度量衡”。**MMD值越大，差异越大；MMD值越小，差异越小**。
>   - TCA 的目标就是**寻找一个投影方向（由转换矩阵W定义），将原始数据投影到一个新的特征空间后，使得源域和目标域在这个新空间里的MMD值最小**。
> - **TCA 是如何寻找这个 W 的？**
>   1. **输入**：`tca.fit(Xs_sample, Xt_sample)`。我们从源域和目标域各取一部分样本数据。
>   2. **目标函数**：算法要解决一个优化问题，通俗地讲就是：
>      - **分子项（最小化）**：投影后，两个域的 MMD 距离要尽可能小。这体现在代码中的 `term_a = K @ L @ K`，其中 `L` 就是MMD矩阵。
>      - **分母项（最大化）**：在投影的过程中，数据本身的结构和信息（方差）要尽可能地被保留下来，不能投完之后所有数据都缩成一团了。这体现在代码中的 `term_b = K @ H @ K`，其中 `H` 是中心化矩阵，用于保留数据方差。
>   3. **求解**：通过求解一个**广义特征值问题**，算法就能找到最优的转换矩阵 `W`。这个 `W` 就是将两个矩阵转化成同一个标准下的桥梁。
>
> #### **第三步：执行迁移 —— 转到标准空间**
>
> 在 `transfer_pipeline.py` 中，我们用学习到的 `W` 来转换**所有**数据。
>
> - **实现**：
>
>   Python
>
>   ```python
>   # 用学习到的规则，转换全部数据
>   Xs_tca = tca.transform(Xs) # 转换完整的源域数据
>   Xt_tca = tca.transform(Xt) # 转换完整的目标域数据
>   ```
>
> - **结果**：`Xs_tca` 和 `Xt_tca` 就是被按标准转化之后的新特征。在 `tsne_after_tca.png` 中，我们看到它们的数据分布已经高度重叠和混合，证明“翻译”成功了，**领域差异被极大地消除了**。
>
> 
>
> #### **第四步：构建新模型 —— 训练“能识别标准的模型”**
>
> 
>
> 现在我们有了用“标准”表达的源域数据 `Xs_tca` 和对应的标签 `ys`。
>
> - **原理**：任务二训练的旧模型只懂旧的数据域中的东西，它搞不懂标准里面的东西。因此，我们必须**构建一个全新的、能够理解“标准”的新模型**。
>
> - **实现**：
>
>   ```python
>   # 在这个对齐后的新空间里，训练一个全新的XGBoost分类器
>   classifier_in_tca_space = XGBClassifier(...)
>   classifier_in_tca_space.fit(Xs_tca, ys) # 在转换后的源域数据上训练
>   ```
>
> - 这个 `classifier_in_tca_space` 就是我们最终的**目标域诊断模型**。它是在消除了领域差异的共享空间中训练出来的，因此具备了从源域向目标域泛化的能力。
>
> 
>
> #### **第五步：应用新模型 —— 诊断目标域**
>
> 
>
> 最后，我们用这个“标准识别模型”去诊断同样被转化成了“标准的目标域数据 `Xt_tca`。
>
> - **实现**：
>
>   Python
>
>   ```
>   # 用新模型对转换后的目标域数据进行预测
>   target_pred_labels_encoded = classifier_in_tca_space.predict(Xt_tca)
>   ```
>
> **总结一下“迁移”的本质**：
>
> 迁移学习不是简单地把旧模型拿来用，而是一个**“学习转换规则 → 执行转换 → 构建新模型 → 应用新模型”**的四步过程。其核心在于通过 **TCA (MMD)** 算法，找到了一个能消除领域差异的“共享特征空间”，并在这个共享空间中重新构建了具备泛化能力的诊断模型，从而实现了知识的有效迁移。

##### 3. 构建目标域诊断模型

迁移学习并非简单地复用旧模型，而是要构建一个适应了新领域的**新模型**。

- **构建过程的体现**：
  - **位置**：在 `src/pipelines/transfer_pipeline.py` 的第5步——**在TCA对齐后的新空间中，训练分类器并进行预**中实现。
  - **核心逻辑**：
    1. 首先，使用TCA算法将**全部的源域数据**和**全部的目标域数据**都转换到对齐后的新特征空间中，得到 `Xs_tca` 和 `Xt_tca`。
    2. 然后，我们**在这个新的、对齐的空间中，用转换后的源域数据 (`Xs_tca`) 及其标签 (`ys`)，从头训练了一个全新的XGBoost分类器** (`classifier_in_tca_space`)。
- **最终的目标域诊断模型**：
  - 这个在新空间中训练出的 `classifier_in_tca_space` **就是我们最终用于目标域诊断的模型**。它在构建时已经充分学习了两个域对齐后的数据分布，因此能够将在源域学到的诊断知识有效地泛化到目标域上。

##### 4. 对目标域数据进行分类、标定，并给出数据对应的标签

这是本题要求的最终“答案”。

- **体现位置**：
  - **分类标定**：在 `src/pipelines/transfer_pipeline.py` 中，我们使用上一步构建的 `classifier_in_tca_space` 对转换后的目标域数据 `Xt_tca` 进行预测。
  - **最终产出文件**：`outputs/predictions/XGBoost/target_preds_tca.csv`
- **产出文件内容解读**：
  - 这个CSV文件就是对目标域未知标签数据的**最终分类和标定结果**。
    - `original_file`: 对应目标域原始数据的文件名（A~P）。
    - `window_id`: 唯一标识这是原始文件中的第几个数据窗口。
    - `predicted_fault_type`: **此列即为模型对该数据窗口的故障类型标定结果**。
    - `proba_*`: 提供了模型预测为每个具体故障类别的置信度概率，可用于评估预测的可靠性。

##### 5. 迁移结果的可视化展示和分析

- **体现位置**：
  - **产出文件**：`outputs/figs/transfer/tsne_after_tca.png`
- **产出文件内容与分析**：
  - 这张图展示了在应用TCA算法后，源域和目标域数据在t-SNE降维空间中的分布情况。
  - **分析**：与迁移前的图像相比，在这张图中，代表源域和目标域的数据点**显著地混合在了一起**。我们可以清晰地看到，不同颜色的簇（代表不同故障类型）是跨越了两个域的，例如，某个代表“内圈故障”的黄色簇中，既包含了源域的彩色点，也包含了目标域的'x'标记。这证明了TCA算法成功地**消除了领域差异**，将两个域的数据分布拉近，是迁移学习有效性的直接视觉证据。

---

#### 相关文件及参数含义

| 文件名 (File Name)                                     | 文件作用 (Role in Workflow) | 文件内容介绍 (Content Description)                           |
| ------------------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| `runs/transfer_tca.yaml`                               | **迁移任务-主配置文件**     | 定义了本次迁移诊断任务的所有配置，包括输入文件路径（如预训练模型、特征集）、TCA算法的核心参数（如目标维度、核函数），以及所有输出产物（预测结果、可视化图像）的路径和命名标签。 |
| `src/pipelines/transfer_pipeline.py`                   | **迁移任务-执行流水线**     | **题目三的核心调度中心**。它负责解析配置文件，加载在任务二中训练好的源域模型、完整的特征数据，并执行完整的迁移学习流程：数据准备 -> TCA领域自适应 -> 在对齐空间中训练新模型 -> 预测目标域标签 -> 保存结果与可视化。 |
| `src/transfer/tca.py`                                  | **迁移任务-核心算法**       | 包含了**迁移成分分析 (TCA)** 算法的完整实现。该脚本定义了如何学习一个能最小化源域和目标域分布差异的转换映射，是实现知识迁移的技术核心。 |
| `outputs/models/source_xgb_baseline.pkl`               | **模型输入-预训练模型**     | 作为迁移学习的**知识来源**。这是在任务二中，仅用源域数据训练好的XGBoost模型。在我们的方案中，虽然没有直接使用它来预测，但我们利用了其训练过程中的数据处理逻辑（如标签编码器）来确保一致性。 |
| `outputs/models/source_xgb_baseline_label_encoder.pkl` | **模型输入-标签编码器**     | 记录了故障类型文本（如'Ball'）与数字（如'1'）之间的映射关系。在迁移流水线中，它被用于编码源域标签以训练新模型，以及在最后将数字预测结果**解码**回人类可读的故障类型文本。 |
| `outputs/data/artifacts/features.parquet`              | **数据输入-完整特征集**     | 作为迁移算法的**数据基础**。它包含了从**所有源域和目标域**数据中提取的完整混合特征。流水线会从此文件中分离出源域和目标域数据，用于后续的领域自适应处理。 |
| `outputs/predictions/XGBoost/target_preds_tca.csv`     | **产出物-目标域诊断结果**   | **题目三的核心答案**。这是一个CSV表格，提供了对目标域未知数据的最终分类和标定。<br /> - `original_file`: 对应目标域原始数据的文件名（A~P）。 <br />- `window_id`: 唯一标识这是原始文件中的第几个数据窗口。 <br />- **`predicted_fault_type`**: **模型对该数据窗口的故障类型标定结果**。 <br />- `proba_*`: 模型预测为每个具体故障类别的**置信度概率**（0到1之间），值越高代表模型对该预测越有信心。 |
| `outputs/figs/transfer/tsne_before_tca.png`            | **产出物-迁移前可视化**     | **领域差异的视觉证明**。这张t-SNE降维图展示了在进行迁移学习之前，源域（蓝色点云）和目标域（红色点云）的数据分布情况。 **如何解读**：图中两个颜色的点云**明显分离**，形成了两个独立的簇。这直观地证明了两个域之间存在显著的**“领域偏移”**，从而确立了进行领域自适应的必要性。 |
| `outputs/figs/transfer/tsne_after_tca.png`             | 产出物-迁移后可视化         | 迁移学习有效性的视觉证据。这张t-SNE图展示了在应用TCA算法，并将数据投影到共享子空间后，源域和目标域数据的分布情况。 如何解读：图中源域和目标域的数据点**显著地混合在了一起**，不同颜色的簇（代表不同故障类型）是跨越了两个域的。这强有力地证明了TCA算法成功地**消除了领域差异**，将两个域的数据分布拉近，为源域知识的有效迁移创造了条件。 |

### 题目四

#### 原题陈述：

 **迁移诊断的可解释性**可解释性是机器学习领域的重要研究方向之一。由于机器学习模型的“黑箱”问题，其迁移和诊断过程难以被观测和理解，这可能造成使用者对模型结果的不信任或盲目信任，进而影响诊断模型的应用。迁移诊断可解释性研究的核心目标是解决迁移学习模型在跨工况、跨设备故障诊断中的透明性问题，提高诊断人员对迁移过程和诊断模型输出的理解和信任度。请考虑任务3中模型的结构设计、迁移过程和决策过程，结合轴承故障特点与故障机理，对迁移诊断的事前/迁移过程/事后（任选一点或多点）可解释性进行分析。

#### 方案概述：

为解决机器学习模型的“黑箱”问题，并建立对诊断结果的信任，题目四要求我们对迁移诊断的过程或结果进行可解释性分析。我们的方案选择聚焦于**事后可解释性 (Post-hoc Interpretability)**，并采用业界领先的 **SHAP (SHapley Additive exPlanations)** 框架来实现。

#### **1. 方案选择：为何采用“事后可解释性”与 SHAP？**

- **问题背景**：我们在任务二和三中构建的诊断模型是 **XGBoost**，这是一种高性能的集成树模型。然而，它的内部决策过程极其复杂，包含了数百棵决策树的集成结果，人类难以直接理解其预测依据，是典型的“黑箱”模型。
- **为何不是“事前可解释性”？**
  - “事前可解释性”要求模型本身结构简单透明，如线性回归或决策树。虽然这类模型易于理解，但它们的性能上限较低，无法充分利用我们在任务一中提取的复杂、高维的混合特征集。为了追求最高的诊断精度，必须使用更强大的“黑箱”模型。
- **为何选择 SHAP？**
  - SHAP 是一种基于合作博弈论的、模型无关的先进解释方法。它有两个核心优势，完美地满足了题目要求：
    1. **坚实的理论基础**：它能保证特征贡献度的分配是公平且唯一的。
    2. **提供全局和局部两种解释**：它不仅能告诉我们模型**整体上**依赖哪些特征，更能为**每一个独立的预测**提供精确的归因分析。这使得我们能够将模型的抽象决策与具体的物理故障机理联系起来。

---

#### **2. 方案实现：可解释性分析流水线**

我们的可解释性分析并非孤立的脚本，而是一个完整、自动化的流水线。

- **实现位置**：
  - 整个分析流程由 `src/pipelines/interpretability_pipeline.py` 脚本执行。
  - 该流水线的配置由 `runs/interpret_shap.yaml` 文件定义。
- **核心逻辑**：
  1. 流水线加载在任务二中训练好的源域 XGBoost 模型 (`source_xgb_baseline.pkl`)。
  2. 加载完整的特征数据集 (`features.parquet`)，并分离出目标域的数据作为待解释的样本。
  3. 使用源域数据的一个子集作为背景数据，初始化一个 `shap.TreeExplainer`（这是专门为XGBoost等树模型优化过的高效解释器）。
  4. 计算目标域每个样本、每个特征的 SHAP 值，这个值定量地表示了该特征对该样本最终预测结果的贡献度。
  5. 生成并保存全局和局部的可解释性图。

---

#### **3. 产出物：结合故障机理的可解释性分析**

流水线的输出产物直接回应了题目“结合轴承故障特点与故障机理，对……可解释性进行分析”的要求。

- **全局解释性分析 (宏观层面)**：

  - **输出文件**：`outputs/figs/interpretability/shap_global_summary.png`
  - **内容与分析**：
    - 这是一张 **SHAP 全局特征重要性图**（蜂群图）。它展示了**哪些特征在整体上对模型的诊断决策影响最大**。
    - **如何结合机理分析**：通过观察这张图，我们可以验证模型是否学习到了正确的物理规律。例如，如果 `env_peak_freq`（包络谱峰值频率）和 `cwt_total_energy`（小波总能量）等特征排在重要性的前列，就**有力地证明了模型成功捕捉到了由故障产生的周期性冲击和瞬态冲击这一核心物理机理**。这回答了“模型主要依赖哪些物理指标进行诊断”的问题，为模型的可靠性提供了宏观证据。

- **局部解释性分析 (微观层面)**：

  - **输出文件**：`outputs/figs/interpretability/` 目录下的多个 `local_explanation_sample_*.png` 文件。

  - **内容与分析**：

    - 这些是针对**单个**目标域样本的 **SHAP 局部解释瀑布图**。每一张图都为一次具体的诊断提供了**精确的、定量的归因**。

    - **如何结合机理分析**：这为诊断人员提供了具体、可信的决策依据，形成了**坚实的证据闭环**。例如，我们可以看着一张图进行分析：

      > “我们将这个样本诊断为‘内圈故障’，**SHAP分析显示**，其主要依据是它的 `env_peak_freq` 特征值很高（瀑布图中的红色长条），这**与内圈故障的理论特征频率高度吻合**。同时，它的 `cwt_total_energy` 也很高，说明存在显著的瞬态冲击。尽管它的 `td_kurtosis`（峭度）偏低（蓝色条块，起反作用），但这不足以改变最终的诊断结论。”

---

#### 相关文件及参数含义

| 文件名 (File Name)                                           | 文件作用 (Role in Workflow) | 文件内容介绍 (Content Description)                           |
| ------------------------------------------------------------ | --------------------------- | ------------------------------------------------------------ |
| `runs/interpret_shap.yaml`                                   | **可解释性-主配置文件**     | 定义了本次可解释性分析任务的所有配置，包括输入文件路径（如预训练模型、特征集）、SHAP分析的核心参数（如背景样本数），以及所有输出图表的路径和命名。 |
| `src/pipelines/interpretability_pipeline.py`                 | **可解释性-执行流水线**     | **题目四的核心调度中心**。它负责解析配置文件，加载在任务二中训练好的源域模型和目标域特征数据，然后调用SHAP库来计算特征贡献度，并生成全局和局部的可解释性分析图。 |
| `outputs/models/source_xgb_baseline.pkl`                     | **分析对象-预训练模型**     | 作为可解释性分析的**核心对象**。SHAP将深入这个“黑箱”模型，探究其内部的决策逻辑和机制。 |
| `outputs/data/artifacts/features.parquet`                    | **分析对象-特征数据**       | 提供了SHAP分析所需的**背景数据**（从源域中采样）和**待解释样本**（目标域数据）。SHAP需要背景数据来计算每个特征的“平均”贡献。 |
| `outputs/figs/interpretability/shap_global_summary.png`      | **产出物-全局可解释性图**   | **宏观层面**解释模型的整体行为，回答“模型在做所有诊断时，通常最看重哪些特征？” <br />**图像解读**： <br />- **纵轴 (Features)**：代表我们提取的每一个物理特征（如`cwt_total_energy`），按其对模型整体影响的重要性从上到下排序。 <br />- **横轴 (SHAP Value)**：代表特征贡献度。**正值**表示该特征的存在将预测**推向**某个故障类别；**负值**则表示**拉离**。 - **数据点**：图中的每一个点都代表目标域中的一个数据窗口。<br /> - **颜色**：点的颜色代表该特征在那个窗口中的**原始数值大小**（通常红色代表数值高，蓝色代表数值低）。<br /> **评判标准**：此图用于验证模型是否学习到了符合物理机理的规律。例如，如果 `env_peak_freq`（包络谱峰频）这一行中，高数值（红点）普遍分布在正SHAP值区域，则说明模型正确地学习到“高包络谱峰频是故障的重要指征”，其决策逻辑是可信的。 |
| `outputs/figs/interpretability/local_explanation_sample_*.png` | **产出物-局部可解释性图**   | **微观层面**解释**单次诊断**的具体原因，回答“为什么这一个样本被诊断为内圈故障？” **图像解读**：这是一个**瀑布图**，展示了特征贡献如何将模型的预测从基准值推向最终值。 <br />- **基准值 `E[f(x)]`**：图底部的灰色基准线，代表模型在所有背景数据上的平均预测概率。 <br />- **条块 (SHAP Values)**：每个条块代表一个特征对本次预测的贡献。  <br />- **红色条块 (推高)**：表示该特征的当前值**增加**了模型预测为某个特定故障的概率。  <br />- **蓝色条块 (拉低)**：表示该特征的当前值**降低**了模型预测为该故障的概率。  <br />- 条块的**长度**代表贡献的大小。 <br />- **最终值 `f(x)`**：图顶部的最终预测概率，是基准值加上所有特征贡献的总和。 **评判标准**：此图为每一次诊断提供了**具体的证据链**。评判其好坏的标准是**“是否符合物理机理和专家经验”**。例如，一个被诊断为“内圈故障”的样本，其局部解释图应该显示 `env_peak_freq` 的值（应接近理论内圈故障频率）是一个主要的红色推高项，这就为这次诊断提供了强有力的、可信的解释。 |

### 附录

#### 特征表

我们在项目中总共提取了四大类特征，分别以 `td_`, `fd_`, `env_`, `cwt_`作为前缀。下面是每一个特征的详细解释。

##### 1. 时域特征 (Time-Domain Features) - 前缀 `td_`

这类特征直接在原始的振动信号波形上进行计算，描述了信号的整体统计特性。

| 特征名                | 中文名   | 定义与物理含义                                               | 诊断意义                                                     |
| --------------------- | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **`td_mean`**         | 均值     | 信号在一段时间内的平均值，反映了信号的直流分量或零线偏移。   | 通常不作为主要的故障指标，但在某些情况下，传感器或系统的偏移可能与异常状态有关。 |
| **`td_std`**          | 标准差   | 信号围绕其均值的波动幅度。                                   | 与信号能量直接相关。当轴承出现故障产生冲击时，振动加剧，标准差通常会**增大**。 |
| **`td_rms`**          | 均方根   | 信号的有效值，是衡量信号能量的最常用指标之一。               | 与标准差类似，是衡量振动烈度的核心指标。故障越严重，振动能量越大，RMS值也**越大**。 |
| **`td_skew`**         | 偏度     | 衡量信号幅值分布的不对称性。正态分布的偏度为0。              | 某些故障（如不对称的磨损）可能会导致信号波形向一个方向偏斜，从而改变偏度值。 |
| **`td_kurtosis`**     | 峭度     | **衡量信号波形的“尖锐”程度或冲击性**。正态分布的峭度为3。    | **非常重要的故障指标**。健康轴承的振动信号接近正态分布，峭度在3附近。当出现局部故障产生**周期性冲击**时，信号波形会变得“尖锐”，峭度值会**显著增大**（例如大于5）。 |
| **`td_max`**          | 最大值   | 信号在一段时间内的幅值峰值。                                 | 直接反映了发生过的最大冲击强度。故障状态下，最大值通常会**增大**。 |
| **`td_min`**          | 最小值   | 信号在一段时间内的幅值谷值。                                 | 与最大值结合使用，可以了解信号的整体动态范围。               |
| **`td_peak_to_peak`** | 峰峰值   | `td_max` - `td_min`，信号的最大动态范围。                    | 故障冲击会同时增大最大值和最小值的绝对值，因此峰峰值也是衡量振动烈度的敏感指标，故障时会**增大**。 |
| **`td_crest_factor`** | 裕度因子 | `td_max` / `td_rms`，峰值与有效值之比。                      | **衡量信号中冲击成分的另一个关键指标**。一个平稳的信号（如正弦波）裕度因子很小，而一个包含显著冲击的信号，其裕度因子会**非常大**。 |
| **`td_shape_factor`** | 波形因子 | `td_rms` / 平均绝对值，反映波形的形状，与功率的集中程度有关。 | 故障信号的波形会发生畸变，该指标可以从另一个角度捕捉这种变化。 |

##### 2. 频域特征 (Frequency-Domain Features) - 前缀 `fd_`

这类特征是对信号进行快速傅里叶变换（FFT）后，在频谱图上进行计算，用于分析信号的频率成分。

| 特征名             | 中文名       | 定义与物理含义                                   | 诊断意义                                                     |
| ------------------ | ------------ | ------------------------------------------------ | ------------------------------------------------------------ |
| **`fd_mean_mag`**  | 频域平均幅值 | 频谱中所有频率分量的幅值大小的平均值。           | 类似于时域的RMS，它从频域角度衡量了信号的**总能量**。故障发生时，总能量通常会**增大**。 |
| **`fd_peak_freq`** | 频谱峰值频率 | 频谱中能量（幅值）最高的那个频率点的频率值(Hz)。 | 如果信号中存在某个主导的周期性成分（例如不平衡或共振），这个指标会捕捉到它。 |
| **`fd_peak_mag`**  | 频谱峰值幅值 | 频谱中能量（幅值）最高的那个频率点的幅值大小。   | 衡量了最主要频率成分的强度。                                 |

##### 3. 包络谱特征 (Envelope Spectrum Features) - 前缀 `env_`

这是**诊断轴承故障最核心**的特征之一。它通过希尔伯特变换先提取信号的包络，再对包络进行FFT，旨在直接寻找由故障引起的**周期性冲击**的频率。

| 特征名              | 中文名         | 定义与物理含义                       | 诊断意义                                                     |
| ------------------- | -------------- | ------------------------------------ | ------------------------------------------------------------ |
| **`env_peak_freq`** | 包络谱峰值频率 | **包络谱中能量最高的频率点(Hz)**。   | **“金标准”故障指标**。这个频率直接对应了故障的**冲击重复频率**。理论上，它应该与轴承的**故障特征频率（BPFO, BPFI, BSF）\**之一相吻合，是判断\**故障类型**（内圈、外圈还是滚动体）的最直接证据。 |
| **`env_peak_mag`**  | 包络谱峰值幅值 | 包络谱中能量最高的频率点的幅值大小。 | 衡量了**周期性冲击的强度**。冲击越剧烈、越有规律，这个值就**越大**。是判断故障严重程度的重要参考。 |

##### 4. 时频域特征 (Time-Frequency Features) - 前缀 `cwt_`

这类特征通过连续小波变换（CWT）计算，能够同时分析信号在**不同时间和不同频率**上的能量分布，特别擅长捕捉**瞬态、非平稳**的信号特征。

| 特征名                          | 中文名         | 定义与物理含义                           | 诊断意义                                                     |
| ------------------------------- | -------------- | ---------------------------------------- | ------------------------------------------------------------ |
| **`cwt_total_energy`**          | 小波总能量     | 在整个时频图上所有能量的总和。           | 从时频域角度衡量信号的总能量。故障（尤其是冲击性故障）会导致能量**增大**。 |
| **`cwt_mean_energy`**           | 小波平均能量   | 在不同尺度（频率）上的小波能量的平均值。 | 衡量了信号在不同频带上能量分布的平均水平。                   |
| **`cwt_std_energy`**            | 小波能量标准差 | 在不同尺度（频率）上的小波能量的标准差。 | 衡量了能量在不同频带上分布的**不均匀程度**。如果能量高度集中在某几个频带，此值会较大。 |
| **`cwt_energy_low_freq_band`**  | 小波低频带能量 | 信号在预定义的低频范围内的总能量。       | 某些故障类型（如不平衡、松动）的能量主要集中在低频，此指标可以有效捕捉它们。 |
| **`cwt_energy_mid_freq_band`**  | 小波中频带能量 | 信号在预定义的中频范围内的总能量。       | 滚动轴承的故障特征频率通常出现在中频段，此指标是**捕捉轴承故障瞬态冲击能量**的关键。 |
| **`cwt_energy_high_freq_band`** | 小波高频带能量 | 信号在预定义的高频范围内的总能量。       | 故障产生的冲击会激发结构的高频共振，此指标可以捕捉到这种现象，对于**早期故障诊断**尤其敏感。 |

#### 图像详解

##### SHAP 全局特征重要性图深度解析 (`shap_global_summary.png`)

**第一步：理解图的总体目标**

这张图的**核心目标**是回答一个问题：“在诊断所有故障样本时，我们的XGBoost模型**在整体上最依赖哪些物理特征**？”

它通过计算每个特征对模型预测的**平均影响幅度**，并将特征从上到下按重要性排序，来直观地展示模型的“决策偏好”。一个特征的条形越长，代表它在模型的成千上万次决策中，平均而言“话语权”越大。

**第二步：解读坐标轴和图例**

- **纵轴 (Y-axis)**：列出了我们提取的物理特征，**按重要性从高到低排列**。例如，`fd_mean_mag` (频域平均幅值) 是模型认为最重要的特征，而 `cwt_energy_low_freq_band` (CWT低频带能量) 则是最不重要的特征之一。
- **横轴 (X-axis)**：`mean(|SHAP value|)`，即**SHAP值的平均绝对值**。这个值可以被理解为**“平均影响模型输出的量级”**。它是一个定量的指标，横轴的值越大，说明这个特征对最终诊断结果的“推力”或“拉力”平均而言就越大。
- **图例 (Legend)**：图中的三种颜色分别对应三种不同的故障类别：
- **蓝色 (InnerRace)**：内圈故障
- **粉色 (Ball)**：滚动体故障
- **橄榄色 (OuterRace)**：外圈故障
- **条形块 (Bars)**：每个特征对应一个**堆叠条形图**。条形的总长度代表该特征的总体重要性。而其中不同颜色分块的长度，则代表该特征对**特定故障类别**预测的平均影响幅度。

**第三步：结合故障机理，分析核心特征**

现在，我们来分析排名前几位的关键特征，看看模型是否学习到了正确的物理规律。

1. **频域特征 (`fd_\*`) 的统治地位**
   - **观察**：排名前三的特征 `fd_mean_mag`, `fd_peak_freq`, `fd_peak_mag` 全部来自频域分析。
   - **机理分析**：轴承故障的本质是周期性冲击，这必然会在频谱上产生显著的能量集中。`fd_mean_mag` (平均幅值) 体现了信号整体能量的增强；`fd_peak_freq` (峰值频率) 和 `fd_peak_mag` (峰值幅值) 则直接定位了能量最集中的频率点及其强度。
   - **模型洞察**：这说明我们的模型首先学习到的最朴素也最有效的规则是：**“当一个轴承信号的整体振动能量变大，并且在某个特定频率点出现了一个高耸的山峰时，它很可能出故障了。”** 这完全符合基础的振动诊断原理。
2. **包络谱特征 (`env_\*`) 的关键作用**
   - **观察**：`env_peak_mag` (包络谱峰值幅值) 和 `env_peak_freq` (包络谱峰值频率) 分别位列第4和第7，是模型决策的核心支柱。
   - **机理分析**：**包络谱分析是诊断轴承故障最经典、最核心的技术**。它通过希尔伯特变换剥离掉高频的固有振动，专门分析由故障冲击引起的**低频周期性**。`env_peak_freq` 直接对应了故障特征频率（BPFO, BPFI, BSF），是判断故障类型的**“身份证”**。
   - **模型洞察**：模型高度依赖包络谱特征，证明了我们的**特征工程是成功的**。它没有陷入无关特征的陷阱，而是准确地抓住了最能反映故障机理的指标。特别值得注意的是，在 `env_peak_mag` 的条块中，**橄榄色 (OuterRace) 占据了很大一部分**。这揭示了一个更深层次的规律：模型认为**包络谱的冲击幅值对于诊断外圈故障尤其重要**。这与物理现实高度吻合，因为外圈故障位置固定，产生的冲击信号最稳定、最清晰。
3. **时域特征 (`td_\*`) 的辅助价值**
   - **观察**：`td_std` (标准差), `td_mean` (均值), `td_kurtosis` (峭度) 等时域特征也具有中等重要性。
   - **机理分析**：峭度 (`td_kurtosis`) 是衡量信号冲击性的经典指标。一个健康的轴承信号峭度值约等于3，而一个有冲击性故障的信号其峭度值会显著增大。
   - **模型洞察**：模型将这些时域特征作为**重要的辅助证据**。例如，当频域和包络谱都出现异常时，如果峭度也很高，模型就更有信心做出故障诊断。

**第四步：意外的发现与反思**

- **观察**：所有与**CWT（连续小波变换）\**相关的特征，如 `cwt_mean_energy` 等，都排在榜单的\**最末尾**，其平均影响几乎为零。
- **机理分析**：CWT的优势在于捕捉信号的**瞬态、非平稳**特性，对于探测早期、微弱的故障信号非常有效。
- **模型洞察与结论**：这个结果出乎意料，但极具启发性。它强烈地暗示，对于**我们当前处理的这个数据集**，故障特征已经足够明显，以至于产生了非常清晰和稳定的**周期性冲击**。在这种情况下，传统的频域和包络谱分析已经足以做出准确诊断，而更复杂、更擅长捕捉微弱瞬态信号的CWT特征就显得**冗余**了。这是一个非常宝贵的结论：**并非越复杂的特征就越好**。这也说明，如果未来我们要处理的是**更早期的、更微弱的**故障信号，CWT特征的重要性可能会大幅提升。

##### SHAP 局部瀑布图深度解析（`local_explanation_sample_0_class_Ball.png`)

这张图的文件名是 `local_explanation_sample_0_class_Ball.png`，这告诉我们，它解释的是：**“对于第0号样本，为什么模型会认为它是一个滚动体故障 (Ball)？”**

**第一步：理解起点和终点**



首先，看图的底部和顶部，这是我们理解整个“决策旅程”的起点和终点。

- **起点 `E[f(x)] = -1.345` (Base Value)**：
  - **指标含义**：这是模型的**“平均认知”**或**“历史经验”**。在不看当前这个样本任何具体特征的情况下，模型根据它在所有训练数据中学到的经验，得出的对“滚动体故障”的平均预测分数是 -1.345 (这是一个对数概率，负数代表平均来看概率小于50%)。你可以把它理解为模型的“无偏见”的出发点。
- **终点 `f(x) = 0.335` (Final Prediction)**：
  - **指标含义**：这是模型在**看完了当前这个样本的所有具体特征值后**，给出的**最终预测分数**。
  - **分析**：分数从 **-1.345** 提升到了 **+0.335**。这个变化是巨大的，说明模型在这个样本中找到了**强有力的证据**，使其**彻底改变了最初的看法**，最终倾向于认为这是一个“滚动体故障”。

接下来的所有内容，都是在解释预测分数是如何从 -1.345 一步步累加到 0.335 的。

**第二步：逐一分析核心特征的“推力”与“拉力”**

现在，我们从下往上（或者按贡献度从大到小）来看每一个特征是如何影响决策的。

1. **`fd_mean_mag = 0.04` (蓝色，SHAP值 = -2.28)**
   - **指标含义**：`fd_mean_mag` 是频域平均幅值，代表了振动信号的**整体能量强度**。
   - **数据解读**：这个样本的整体振动能量**非常低**（仅为 0.04）。
   - **决策分析（强烈的“拉力”）**：这是**最强的、反对**当前诊断的证据。模型认为：“一个故障轴承的振动能量通常会显著增强，而这个样本的能量如此之低，这强烈地暗示它是一个**健康**的轴承。” 这个特征一个就把预测分数向左（负方向）猛拉了 **2.28**，让模型极度不相信这是一个故障。
2. **`fd_peak_freq = 1324.219` (红色，SHAP值 = +1.32)**
   - **指标含义**：`fd_peak_freq` 是频谱中能量最高的**峰值频率**。
   - **数据解读**：信号中存在一个位于 **1324.219 Hz** 的显著能量峰。
   - **决策分析（强烈的“推力”）**：这是**最重要的、支持**诊断的证据。模型认为：“尽管整体能量很低，但在 1324 Hz 这个不寻常的频率点上出现了能量集中。根据我学到的知识，这个频率很可能与滚动体的某种特定故障模式（例如自旋频率的谐波）高度相关。” 这个强有力的证据，开始**对抗**前一个特征的“拉力”，将预测分数向右（正方向）推了 **1.32**。
3. **`td_shape_factor = 1.253` (红色，SHAP值 = +0.73)**
   - **指标含义**：`td_shape_factor` 是时域波形形态因子，反映了波形的形状。
   - **数据解读**：该样本的波形形态因子为 1.253。
   - **决策分析（中等强度的“推力”）**：模型从训练中学到，值为 1.253 的波形形态因子是“滚动体故障”的另一个特征。它为“滚动体故障”的诊断结论，又增加了一份权重为 **+0.73** 的支持证据。
4. **`td_kurtosis = 0.01` (红色，SHAP值 = +0.31)**
   - **指标含义**：`td_kurtosis` 是峭度，衡量信号的**冲击性**。
   - **数据解读**：峭度值仅为 0.01，非常低，表明信号波形平缓，缺少冲击。
   - **决策分析（较弱的“推力”）**：这是一个非常有趣的发现。通常低峭度是健康轴承的标志。但在这里它却提供了一个微弱的“推力”。这揭示了模型决策的复杂性：**在某些特征（如`fd_peak_freq`）已经出现异常的上下文中，一个较低的峭度值可能反而成为了某种特定亚类滚动体故障的佐证**。这也说明了单一指标判断的局限性和SHAP解释复杂模型的价值。
5. **`env_peak_freq = 64.453` (红色，SHAP值 = +0.16)**
   - **指标含义**：`env_peak_freq` 是**包络谱的峰值频率**，这是诊断轴承故障的**“金标准”**，直接对应故障的周期性冲击频率。
   - **数据解读**：在包络谱中，存在一个 **64.453 Hz** 的峰。
   - **决策分析（较弱但关键的“推力”）**：这个频率很可能就是**滚动体故障特征频率 (BSF)** 或其相关频率。虽然它在这里的SHAP值不是最大，但它的出现是符合物理机理的、非常关键的证据，为诊断结论提供了 **+0.16** 的支持。

**第三步：综合所有证据，得出最终结论**

将所有特征的“推力”（红色条块）和“拉力”（蓝色条块）相加，我们可以清晰地看到整个决策过程：

> **诊断**：模型最初的判断（-1.345）是“不像滚动体故障”。然后，一个极强的反面证据 `fd_mean_mag`（低能量）出现，将判断进一步拉向“健康”（分数被拉低到 -1.345 - 2.28 = -3.625）。
>
> **然而**，一个同样强力的正面证据 `fd_peak_freq`（特定频率峰值）出现了，将局势向“故障”方向扭转。随后，`td_shape_factor`、`td_kurtosis`、`env_peak_freq` 等一系列**支持性证据（尽管单个力量不强）不断累加**，最终将所有的“拉力”全部抵消，并把最终的预测分数推高到了 **+0.335**，从而完成了这次“逆风翻盘”式的诊断。

这张图展示了模型是如何权衡各种相互矛盾的证据，并最终依据占优的证据链条，做出最终诊断的。