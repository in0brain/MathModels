# 2025年华为杯E题：高铁轴承智能故障诊断的全流程实现

本文档详细介绍了为解决“2025年中国研究生数学建模竞赛E题 - 高铁轴承智能故障诊断问题”而构建的一个模块化、可复现的端到端工作流。该工作流遵循\*\*“机理先行、统计为核、迁移对齐、证据闭环”\*\*的核心思想，通过一系列自动化的数据处理、模型训练、迁移学习和可解释性分析流水线，系统地解决了从数据准备到最终诊断和分析的所有挑战。

## 一、项目模块概览

为解决此问题，项目结构扩展如下，新增了针对振动信号处理、迁移学习和可解释性分析的核心模块：

```
MathModels/
└── src/
    ├── models/
    │   └── clf/
    │       └── XGBoost/             # 核心分类器模块
    │           ├── build.py
    │           └── params.yaml
    ├── pipelines/
    │   ├── clf_pipeline.py          # 分类模型训练流水线
    │   ├── preprocess_pipeline.py   # 数据预处理流水线
    │   ├── transfer_pipeline.py     # (新增) 迁移诊断流水线
    │   └── interpretability_pipeline.py # (新增) 可解释性分析流水线
    ├── preprocessing/
    │   └── signal/                  # (新增) 信号数据预处理模块
    │       ├── load_bearing_data.py
    │       ├── feature_extraction.py
    │       ├── steps_load_data.yaml
    │       └── steps_feature_extraction.yaml
    └── transfer/
        └── tca.py                   # (新增) TCA迁移算法实现
```

-----

## 二、题目一 & 二：数据分析、特征提取与源域诊断

此阶段的目标是处理原始数据，提取一个包含丰富信息的混合特征集，并在此基础上训练一个高性能的源域诊断模型。

### **阶段 1：原始数据加载与结构化**

  - **目标**：将分散的 `.mat` 格式数据转换为统一的 Parquet 格式，并生成一份总的元数据清单 `manifest.csv`。
  - **实现**：`src/preprocessing/signal/load_bearing_data.py` 脚本递归搜索所有 `.mat` 文件，解析文件名以提取元信息，并将信号数据保存为独立的 Parquet 文件。
  - **配置文件**：`src/preprocessing/signal/steps_load_data.yaml`

### **阶段 2：信号处理与混合特征提取**

  - **目标**：对结构化的信号数据进行标准化处理（重采样、分窗），并提取一个**多模态混合特征集**，最终生成可供机器学习模型使用的特征表 `features.parquet`。
  - **实现**：`src/preprocessing/signal/feature_extraction.py` 脚本实现了对每个信号窗口的特征提取，**完全对齐了我们的增强方案**：
      - **时域特征**：提取 RMS、峭度、裕度等10个统计指标。
      - **频域特征 (FFT)**：提取峰值频率、峰值幅值等关键频域指标。
      - **包络谱特征 (Hilbert)**：提取包络谱中的峰值频率，以识别与故障机理相关的周期性冲击。
      - **时频域特征 (CWT)**：利用连续小波变换提取不同频带的能量，有效捕捉信号的瞬态、非平稳特征。
  - **配置文件**：`src/preprocessing/signal/steps_feature_extraction.yaml`

### **阶段 3：源域故障诊断 (XGBoost)**

  - **目标**：利用提取出的强大混合特征集，在源域数据上训练一个高性能、高鲁棒性的 XGBoost 基线模型。
  - **实现**：`src/models/clf/XGBoost/build.py` 脚本负责：
      - 加载 `features.parquet` 特征表。
      - 采用 `StratifiedGroupKFold` 策略进行严格的**防数据泄漏划分**，确保来自同一原始文件的窗口不会同时出现在训练集和验证集。
      - 训练 XGBoost 分类器并进行性能评估。
  - **配置文件**：`src/models/clf/XGBoost/params.yaml`

-----

## 三、题目三：迁移诊断

此阶段的核心任务是将在源域学到的诊断知识迁移至无标签的目标域，并对目标域数据进行故障分类和标定。

### **方法：基于最大均值差异(MMD)的迁移成分分析(TCA)**

我们采用基于特征迁移的TCA算法。其核心思想是学习一个映射，将源域和目标域的数据投影到一个共享的潜在子空间中。在这个子空间里，通过最小化MMD损失，使得两个域的数据分布尽可能对齐。这样，在源域上训练的分类器就能更好地泛化到对齐后的目标域数据上。

### **实现与执行**

  - **流水线脚本**：`src/pipelines/transfer_pipeline.py`
  - **核心逻辑**：
    1.  加载在题目二中训练好的源域XGBoost模型 (`source_xgb_baseline.pkl`)。
    2.  加载完整的特征数据集 (`features.parquet`)，并分离源域和目标域。
    3.  应用我们实现的TCA算法 (`src/transfer/tca.py`)，将源域和目标域特征映射到对齐的潜在空间。
    4.  使用源域模型对**转换后**的目标域数据进行预测，完成对目标域的故障标定。
    5.  生成**迁移前/后**的t-SNE降维可视化图，直观展示TCA的领域对齐效果。
  - **配置文件**：`runs/transfer_tca.yaml`
  - **执行命令**：
    ```bash
    python -m src.pipelines.transfer_pipeline --config runs/transfer_tca.yaml
    ```
  - **核心产出**：
      - `outputs/predictions/XGBoost/target_preds_tca.csv`：**目标域数据的预测标签**，完成了题目要求的分类和标定任务。
      - `outputs/figs/transfer/tsne_before_tca.png` 和 `tsne_after_tca.png`：**迁移过程的可视化**，清晰地展示了源域和目标域数据分布从“分离”到“融合”的过程。

-----

## 四、题目四：迁移诊断的可解释性

为解决机器学习模型的“黑箱”问题，我们引入SHAP框架，对训练好的XGBoost模型进行事后可解释性分析，以建立对模型诊断结果的信任。

### **方法：SHAP (SHapley Additive exPlanations)**

SHAP是一种基于博弈论的先进方法，它能将模型的单个预测结果解释为各个输入特征的贡献值之和。我们用它来提供全局和局部两个层面的解释。

### **实现与执行**

  - **流水线脚本**：`src/pipelines/interpretability_pipeline.py`
  - **核心逻辑**：
    1.  加载训练好的XGBoost模型和特征数据。
    2.  初始化一个`shap.TreeExplainer`。
    3.  计算目标域样本的SHAP值。
    4.  生成并保存全局和局部的可解释性图。
  - **配置文件**：`runs/interpret_shap.yaml`
  - **执行命令**：
    ```bash
    python -m src.pipelines.interpretability_pipeline --config runs/interpret_shap.yaml
    ```
  - **核心产出与分析**：
      - `outputs/figs/interpretability/shap_global_summary.png`：**全局特征重要性图**。此图展示了哪些特征（如`cwt_total_energy`, `env_peak_freq`等）在整体上对模型的诊断决策影响最大，揭示了模型的宏观行为模式。
      - `outputs/figs/interpretability/local_explanation_sample_*.png`：**局部解释瀑布图**。这些图为单个目标域样本提供了精确的归因分析，清晰地展示了每个特征的具体值是如何将预测“推向”（红色）或“拉离”（蓝色）某个故障类别的，为诊断人员提供了具体、可信的决策依据。

-----

## 五、完整工作流执行命令

请在项目根目录下，严格按照以下顺序执行所有命令，即可一键完成从数据处理到最终分析的全过程。

**前置准备：**

1.  将原始数据放入 `data/source_domain` 和 `data/target_domain`。
2.  在 `src/preprocessing/signal/steps_load_data.yaml` 中配置好正确的路径。
3.  安装所有依赖，包括 `PyWavelets` 和 `shap`。
4.  **（强烈建议）** 如果重复运行，请先手动删除 `outputs` 文件夹，确保结果不被缓存影响。

**执行命令：**

```bash
# === 题目 1 & 2：数据处理与源域模型训练 ===
# 1. 加载和结构化原始数据
python -m src.pipelines.preprocess_pipeline --config src/preprocessing/signal/steps_load_data.yaml

# 2. 提取混合特征 (包含CWT)
python -m src.pipelines.preprocess_pipeline --config src/preprocessing/signal/steps_feature_extraction.yaml

# 3. 训练源域诊断模型
python -m src.pipelines.clf_pipeline --config src/models/clf/XGBoost/params.yaml

# === 题目 3：迁移诊断与目标域标定 ===
# 4. 执行TCA迁移并预测目标域标签
python -m src.pipelines.transfer_pipeline --config runs/transfer_tca.yaml

# === 题目 4：可解释性分析 ===
# 5. 生成SHAP图，解释模型决策
python -m src.pipelines.interpretability_pipeline --config runs/interpret_shap.yaml
```

执行完毕后，所有产出物将自动生成在 `outputs` 文件夹的对应子目录中，形成一套完整的、从数据到洞察的解决方案。

---

## 六、工作流深度解析：从决策到实现

本章节旨在深入剖析整个工作流中关键技术环节的决策过程，并对各阶段的产出物进行详细解读。我们将结合题目要求，阐述在算法选择、参数设定和数据处理策略上的思考，以回答“为什么这么做”的问题。

### **题目一：数据分析与故障特征提取**

**目标**：构建一个信息丰富、鲁棒且有利于后续迁移任务的特征表示体系。

#### **决策一：为何要将原始数据预处理为序列化的 Parquet 格式和 Manifest 清单？**

* **理由与权衡**：
    * **备选方案**：在每次运行时直接从多层级的文件夹中读取并解析所有的 `.mat` 文件。
    * **问题分析**：题目给出的数据分散在复杂的目录结构中，且文件名格式多样。每次都从头扫描和解析，不仅会极大地拖慢实验速度，而且使得整个流程变得脆弱，难以管理和复现。
    * **决策**：我们选择**“一次加载，多次使用”**的策略。首先通过一个独立的预处理任务 (`load_bearing_data.py`)，将所有原始数据转换成统一、高效的格式，并生成一个元数据总清单。

* **产出物解读**：
    * `outputs/data/artifacts/signal_parquet/` (文件夹):
        * **内容**：存放所有单个信号的 **Parquet 文件**。
        * **如何解读**：每个文件都是一段纯净的、一维的振动信号数组。选择 Parquet 格式是因为其作为列式存储，对纯数值数组的读取速度远超 CSV 或 `.mat`，且压缩率更高，极大地提升了后续特征提取步骤的 I/O 效率。
    * `outputs/data/artifacts/manifest.csv` (文件):
        * **内容**：**元数据总清单**，记录了每个信号的来源文件、故障类型、工况、所属域（源/目标）以及其对应的 Parquet 文件路径。
        * **如何解读**：这是承上启下的**“数据地图”**。后续所有步骤（特征提取、模型训练、迁移）都将依赖此文件来索引数据，而不是混乱的文件系统。这确保了流程的**可追溯性**（知道每个数据点来自哪里）和**可复现性**（更换环境后只需修改`steps_load_data.yaml`中的路径即可）。

#### **决策二：为何选择24kHz作为统一重采样率？**

* **理由与权衡**：
    * [cite_start]**问题背景**：题目给出的源域数据采样率为 12kHz 和 48kHz，目标域为 32kHz [cite: 6]。采样率不统一，会导致频率相关的特征（如FFT、包络谱）不具可比性，模型无法学习到通用的诊断模式。
    * **决策依据（奈奎斯特采样定理与工程实际）**：
        1.  **信息保留**：轴承故障的特征频率（BPFO, BPFI, BSF）及其谐波通常集中在中低频段，远低于 12kHz。根据奈奎斯特采样定理，要无失真地恢复一个信号，采样率需至少是其最高频率成分的两倍。因此，24kHz 的采样率足以完整保留最高 12kHz 的频率信息，这意味着对于原始 12kHz 的数据，我们没有损失任何信息。
        2.  **计算效率**：将 48kHz 和 32kHz 的数据**降采样**至 24kHz，可以在不损失关键故障信息的前提下，**显著降低后续计算（尤其是计算成本高昂的CWT）的复杂度**，加快实验迭代速度。
        3.  **一致性**：将 12kHz 的数据**升采样**至 24kHz，确保了所有信号都在一个统一的时间和频率尺度上进行分窗和特征提取。
    * **结论**：24kHz 是一个在**信息保真度**和**计算效率**之间取得最佳平衡的理想选择。

#### **决策三：为何构建混合特征模型，而非独立分析时域、频域和时频域？**

* **理由与权衡**：
    * **备选方案**：分别提取时域、频域、时频域特征，然后为每一组特征训练一个独立的诊断模型（如SVM、随机森林），最后通过投票或加权的方式融合最终结果。
    * **问题分析**：
        1.  **信息割裂**：故障的完整物理模式是跨域的。例如，一个时域上的强烈冲击（高峭度）只有在频域的特定故障频率或时频域的瞬态能量集中同时出现时，才具有高置信度。独立模型无法学习这种**跨域特征之间的复杂交互关系**。
        2.  **融合困难**：如何确定最终的模型融合权重是一个难题，往往依赖经验，难以达到最优，且增加了系统的复杂性。
    * **决策**：我们将所有域的特征**拼接（concatenate）**成一个高维特征向量，然后输入给一个强大的 **XGBoost** 模型。
        -   **核心优势**：XGBoost 这类集成树模型极其擅长在高维空间中自动学习特征之间的非线性关系和高阶交互作用。它能够自己发现“当 `td_kurtosis` 很高 **且** `env_peak_freq` 接近内圈故障频率 **且** `cwt_energy_mid_freq_band` 也很高时，这是一个内圈故障”这样的复杂规则。这**将特征融合的难题交给了模型去最优化**，效果远胜于人为设计的融合规则。

### **题目二：源域故障诊断**

**目标**：在题目一提取的特征基础上，设计并评估一个高性能的源域诊断模型。

* **产出物解读**：
    * `outputs/models/source_xgb_baseline.pkl` (文件):
        * **内容**：训练好的 XGBoost 模型对象，已序列化。
        * **如何解读**：这是**知识的载体**。它封装了从源域数据中学到的关于不同故障类型的诊断规则。后续的迁移和可解释性分析都将围绕这个核心模型展开。
    * `outputs/reports/source_xgb_baseline_metrics.json` (文件):
        * **内容**：JSON 格式的性能报告，包含 `ACC`, `F1`, `ROC_AUC` 等指标。
        * **如何解读**：
            * **`ACC` (Accuracy)**：**准确率**，表示模型在验证集上正确分类的样本比例。是模型整体性能的直观体现。
            * **`F1` (Macro F1-Score)**：**宏平均F1分数**。F1分数是精确率和召回率的调和平均数。使用“宏平均”意味着对每个故障类别独立计算F1分数再取平均，这在**处理类别不均衡（如正常样本较少）的数据时，比准确率更能公平地评估模型对每个类别的识别能力**。
            * **`ROC_AUC` (Area Under ROC Curve)**：**ROC曲线下面积**。衡量模型在所有分类阈值下区分正负样本的能力，值越接近1，说明模型的区分能力越强。
    * `outputs/figs/clf/source_xgb_baseline_cm.png` (图像):
        * **内容**：**混淆矩阵**的可视化图像。
        * **如何解读**：矩阵的**对角线**上的数值表示模型**正确分类**的样本数量。非对角线上的数值表示模型**错误分类**的样本数量（例如，将'Ball'错误预测为'InnerRace'）。通过观察混淆矩阵，可以直观地分析模型**在哪几类故障之间更容易混淆**，从而为模型的进一步优化提供方向。

### **题目三：迁移诊断**

**目标**：将源域知识迁移至目标域，对无标签的目标域数据进行分类标定，并可视化迁移过程。

* **产出物解读**：
    * `outputs/predictions/XGBoost/target_preds_tca.csv` (文件):
        * **内容**：对目标域每个数据窗口的**故障类型预测结果**。
        * **如何解读**：这是题目3的**最终答案**。`predicted_fault_type` 列给出了模型对每个未知样本的标定结果。同时，`proba_*` 列给出了模型预测为每个具体故障类别的**置信度概率**，这为评估预测结果的可靠性提供了重要参考。
    * `outputs/figs/transfer/tsne_before_tca.png` & `tsne_after_tca.png` (图像):
        * **内容**：使用t-SNE降维算法对迁移前、后数据的二维分布可视化。
        * **如何解读**：
            * **`tsne_before_tca.png`**：在这张图中，代表源域的蓝色点云和代表目标域的红色点云通常会形成**分离或部分重叠**的两个簇。这直观地展示了由工况差异导致的**“领域偏移”**问题。
            * **`tsne_after_tca.png`**：在应用TCA算法后，这张图展示了在新的特征空间中，源域（彩色点，按真实标签着色）和目标域（'x'标记，按预测标签着色）的数据点**显著地混合在了一起**。这证明TCA成功地**拉近了两个域的分布距离**，为源域模型在目标域上的成功应用创造了条件，是迁移学习有效性的直接视觉证据。

### **题目四：迁移诊断的可解释性**

**目标**：打开XGBoost的“黑箱”，为模型的诊断决策提供透明、可信的解释。

* **产出物解读**：
    * `outputs/figs/interpretability/shap_global_summary.png` (图像):
        * **内容**：**SHAP全局特征重要性图**（通常是蜂群图或条形图）。
        * **如何解读**：此图展示了哪些特征在**整体上**对模型的诊断决策影响最大。每一行代表一个特征，横轴是SHAP值（特征对预测的贡献度）。点的颜色表示特征值的大小（红高蓝低）。例如，如果`cwt_total_energy`一行中，靠右侧（正SHAP值）的点大多是红色的，则说明**高的CWT总能量**是模型预测**存在故障**的重要依据。这回答了“模型主要依赖哪些物理指标进行诊断”的问题。
    * `outputs/figs/interpretability/local_explanation_sample_*.png` (图像):
        * **内容**：针对**单个**目标域样本的**SHAP局部解释瀑布图**。
        * **如何解读**：这是**事后可解释性**的核心。从底部的“基础值”（模型在所有背景样本上的平均预测）出发，每个红色的条块代表一个将预测概率**推高**的特征及其贡献值，每个蓝色的条块代表一个将预测概率**拉低**的特征。最终顶部的 `f(x)` 值就是该样本的最终预测概率。这张图为诊断人员提供了**具体、可信的决策依据**，例如：“我们将这个样本诊断为‘内圈故障’，主要是因为它的`env_peak_freq`很高，同时`td_kurtosis`也偏高，尽管它的`cwt_energy_low_freq_band`较低，但这不足以改变最终判断。”